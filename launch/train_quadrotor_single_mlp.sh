#!/bin/bash
python -m algorithms.appo.train_appo --env=quadrotor_single \
 --train_for_seconds=3600000 \
 --algo=APPO \
 --gamma=0.99 \
 --use_rnn=False \
 --num_workers=20 \
 --num_envs_per_worker=8 \
 --num_policies=1 \
 --ppo_epochs=1 \
 --rollout=128 \
 --recurrence=1 \
 --batch_size=1024 \
 --nonlinearity=tanh \
 --actor_critic_share_weights=False \
 --policy_initialization=xavier_uniform \
 --adaptive_stddev=False \
 --hidden_size=64 \
 --with_vtrace=False \
 --max_policy_lag=100000000 \
 --gae_lambda=1.00 \
 --max_grad_norm=0.0 \
 --experiment=quads_single_v102 \
 --exploration_loss_coeff=0.0